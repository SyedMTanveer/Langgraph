{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ef597741-3211-4ecc-92f7-f58023ee237e",
   "metadata": {
    "id": "ef597741-3211-4ecc-92f7-f58023ee237e"
   },
   "source": [
    "# LangChain Academy\n",
    "\n",
    "Welcome to LangChain Academy!\n",
    "\n",
    "## Context\n",
    "\n",
    "At LangChain, we aim to make it easy to build LLM applications. One type of LLM application you can build is an agent. There’s a lot of excitement around building agents because they can automate a wide range of tasks that were previously impossible.\n",
    "\n",
    "In practice though, it is incredibly difficult to build systems that reliably execute on these tasks. As we’ve worked with our users to put agents into production, we’ve learned that more control is often necessary. You might need an agent to always call a specific tool first or use different prompts based on its state.\n",
    "\n",
    "To tackle this problem, we’ve built [LangGraph](https://langchain-ai.github.io/langgraph/) — a framework for building agent and multi-agent applications. Separate from the LangChain package, LangGraph’s core design philosophy is to help developers add better precision and control into agent workflows, suitable for the complexity of real-world systems.\n",
    "\n",
    "## Course Structure\n",
    "\n",
    "The course is structured as a set of modules, with each module focused on a particular theme related to LangGraph. You will see a folder for each module, which contains a series of notebooks. A video will accompany each notebook to help walk through the concepts, but the notebooks are also stand-alone, meaning that they contain explanations and can be viewed independent of the videos. Each module folder also contains a `studio` folder, which contains a set of graphs that can be loaded into [LangGraph Studio](https://github.com/langchain-ai/langgraph-studio), our IDE for building LangGraph applications.\n",
    "\n",
    "## Setup\n",
    "\n",
    "Before you begin, please follow the instructions in the `README` to create an environment and install dependencies.\n",
    "\n",
    "## Chat models\n",
    "\n",
    "In this course, we'll be using [Chat Models](https://python.langchain.com/v0.2/docs/concepts/#chat-models), which do a few things take a sequence of messages as inputs and return chat messages as outputs. LangChain does not host any Chat Models, rather we rely on third party integrations. [Here](https://python.langchain.com/v0.2/docs/integrations/chat/) is a list of 3rd party chat model integrations within LangChain! By default, the course with use [GEMINI_API_KEY](https://ai.google.dev/gemini-api/docs/api-key/) because it is both popular and performant. As noted, please ensure that you have an `GEMINI_API_KEY`.\n",
    "\n",
    "Let's check that your `GEMINI_API_KEY` is set and, if not, you will be asked to enter it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0f9a52c8",
   "metadata": {
    "id": "0f9a52c8"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.3.1 -> 24.3.1\n",
      "[notice] To update, run: C:\\Users\\Dell\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%%capture --no-stderr\n",
    "!pip install -q langchain_google_genai langchain_core langchain_community tavily-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "85aab84a",
   "metadata": {},
   "outputs": [],
   "source": [
    "GEMINI_API_KEY = \"AIzaSyBZ897ngkx1hRF6VCTU3dY14oaZQQq2kKo\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "Ch7HciDZXh3F",
   "metadata": {
    "id": "Ch7HciDZXh3F"
   },
   "outputs": [],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "llm = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-1.5-flash\",\n",
    "    api_key=GEMINI_API_KEY,\n",
    "    temperature=0\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "KKnOnfj3YZYT",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KKnOnfj3YZYT",
    "outputId": "e5695af8-8f9d-47c4-c5ed-38c28164bd07"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='The 2024 US presidential election has not yet happened.  The election will be held in November 2024.\\n', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': []}, id='run-9056eea4-6f7a-46fd-99f6-9a66b7955436-0', usage_metadata={'input_tokens': 13, 'output_tokens': 29, 'total_tokens': 42, 'input_token_details': {'cache_read': 0}})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result  = llm.invoke(\"Who won 2024 US presidential ellection?\")\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28450d1b",
   "metadata": {
    "id": "28450d1b"
   },
   "source": [
    "Chat models in LangChain have a number of [default methods](https://python.langchain.com/v0.2/docs/concepts/#runnable-interface). For the most part, we'll be using:\n",
    "\n",
    "* `stream`: stream back chunks of the response\n",
    "* `invoke`: call the chain on an input\n",
    "\n",
    "And, as mentioned, chat models take [messages](https://python.langchain.com/v0.2/docs/concepts/#messages) as input. Messages have a role (that describes who is saying the message) and a content property. We'll be talking a lot more about this later, but here let's just show the basics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b1280e1b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b1280e1b",
    "outputId": "040dbd0b-5e22-4044-b9a1-3fc7f55394a5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='There are several ways to learn LangChain, depending on your learning style and prior experience:\\n\\n**1. Official Documentation:** The best place to start is the official LangChain documentation.  It\\'s well-structured and provides comprehensive tutorials and examples.  Look for their \"Getting Started\" guides and work your way through the examples.\\n\\n**2. Tutorials and Blog Posts:** Many tutorials and blog posts are available online that cover various aspects of LangChain. Search for \"LangChain tutorial\" or \"LangChain examples\" on Google, YouTube, and Medium.  Look for tutorials that focus on specific use cases that interest you, such as building chatbots, question-answering systems, or document summarizers.\\n\\n**3. GitHub Repository:** Explore the LangChain GitHub repository.  You can find the source code, contribute to the project, and see how different components are implemented.  Reading the code can be a great way to deepen your understanding.\\n\\n**4. Example Projects:**  The best way to learn is by doing.  Start with a simple project, such as building a basic chatbot or a document question-answering system.  LangChain provides many examples to get you started.  Gradually increase the complexity of your projects as you gain more experience.\\n\\n**5. Courses and Workshops:** While not as prevalent as for some other technologies, you might find online courses or workshops specifically on LangChain or related topics like LLM application development.  Check platforms like Coursera, Udemy, and edX.\\n\\n**6. Community:** Engage with the LangChain community.  Ask questions on forums, participate in discussions, and learn from others\\' experiences.  This can be a valuable resource for troubleshooting and getting help with specific problems.\\n\\n\\n**To get started quickly, I recommend:**\\n\\n* **Visiting the official LangChain documentation:** This is your primary resource.\\n* **Choosing a simple project:**  Don\\'t try to build something overly complex at first.  Start with a small, achievable goal.\\n* **Breaking down the problem:** Divide your project into smaller, manageable tasks.\\n* **Iterating and experimenting:** Don\\'t be afraid to experiment and try different approaches.\\n\\n\\nRemember that LangChain is built upon other libraries and concepts, so having a basic understanding of Python and potentially some familiarity with LLMs will be beneficial.  If you lack these prerequisites, consider learning those first before diving into LangChain.\\n', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': []}, id='run-7f3f6aad-ff01-4bbc-9fa3-474e7a57c0ef-0', usage_metadata={'input_tokens': 39, 'output_tokens': 498, 'total_tokens': 537, 'input_token_details': {'cache_read': 0}})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "\n",
    "# Create a message\n",
    "# Message list\n",
    "messages = [\n",
    "    HumanMessage(content=\"Hi\", name=\"Tanveer\"),\n",
    "    AIMessage(content='Hi! How can I help you today? \\n', name=\"AI Assistant\"),\n",
    "    HumanMessage(content=\"What is LangChain?\", name=\"Tanveer\"),\n",
    "    AIMessage(content='LangChain is a framework for developing applications powered by language models.', name=\"AI Assistant\"),\n",
    "    HumanMessage(content=\"How can I learn\", name=\"Tanveer\"),\n",
    "    ]\n",
    "\n",
    "# Invoke the model with a list of messages\n",
    "llm.invoke(messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cac73e4c",
   "metadata": {
    "id": "cac73e4c"
   },
   "source": [
    "We get an `AIMessage` response. Also, note that we can just invoke a chat model with a string. When a string is passed in as input, it is converted to a `HumanMessage` and then passed to the underlying model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "582c0e5a",
   "metadata": {
    "id": "582c0e5a"
   },
   "source": [
    "The interface is consistent across all chat models and models are typically initialized once at the start up each notebooks.\n",
    "\n",
    "So, you can easily switch between models without changing the downstream code if you have strong preference for another provider.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ad0069a",
   "metadata": {
    "id": "3ad0069a"
   },
   "source": [
    "## Search Tools\n",
    "\n",
    "You'll also see [Tavily](https://tavily.com/) in the README, which is a search engine optimized for LLMs and RAG, aimed at efficient, quick, and persistent search results. As mentioned, it's easy to sign up and offers a generous free tier. Some lessons (in Module 4) will use Tavily by default but, of course, other search tools can be used if you want to modify the code for yourself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "52d69da9",
   "metadata": {
    "id": "52d69da9"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "TAVILY_API_KEY = \"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\"\n",
    "os.environ[\"TAVILY_API_KEY\"] = TAVILY_API_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "490c35f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "tavily_search = TavilySearchResults(max_results=3)\n",
    "search_docs = tavily_search.invoke(\"Who won 2024 US presidential ellection?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "JWzZ6zAvb2Fv",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JWzZ6zAvb2Fv",
    "outputId": "c25d7fa9-cdf6-41c6-f7db-acfc7c54c944"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'url': 'https://www.indystar.com/story/news/politics/elections/2024/11/06/2024-us-election-results-today-who-won-united-states-presidential-election-november-5-usa-elections/76076772007/',\n",
       "  'content': \"2024 United States presidential election results: Who won US President? Election Day 2024 has come and gone as the dust settles in the battle between Donald Trump\\xa0and\\xa0Kamala Harris\\xa0for President of the United States. Indiana was one of several states to back Trump as their candidate of choice in election results, who ultimately received the 270 electoral votes required Tuesday night to secure the presidency. 2024 US presidential election results: Who won President of the United States − Donald Trump or Kamala Harris? 2024 US presidential election live results map by state: Who won President of the United States − Donald Trump or Kamala Harris? Visit indystar.com/elections/results to see Tuesday's U.S. presidential voting results map by state.\"},\n",
       " {'url': 'https://www.bbc.com/news/election/2024/us/results',\n",
       "  'content': 'US Presidential Election Results 2024 - BBC News Close menu BBC News Kamala Harris of the Democrat party has 0 electoral college votes. Donald Trump of the Republican party has 0 electoral college votes. Kamala Harris of the Democrat party has 158,810 votes (38.4%) Donald Trump of the Republican party has 249,225 votes (60.2%) US presidential election results 2024 US election 2024 Voting in some states is particularly hard to predict, with polls showing they could be won by the Republicans or the Democratic party. The battleground states that could decide the 2024 presidential election are: Voters in 11 states will also elect a governor. US election polls: Who is ahead - Harris or Trump? US election 2024 About the BBC'},\n",
       " {'url': 'https://www.latimes.com/politics/story/2024-11-06/trump-defeats-harris-47th-president-election-2024',\n",
       "  'content': 'Trump wins 2024 U.S. presidential election - Los Angeles Times Trump elected 47th president of the United States, defeating Harris to retake White House Nancy Northup, President and CEO of the Center for Reproductive Rights, called Trump’s win “a deadly threat to the democratic values of liberty and equality, the rule of law, and reproductive health, rights, and justice in the United States and around the globe.” “The Democrats thought there were enough people who hated Trump or were willing to fear him to win the race,” Jennings said. 2024 election results: Trump wins second term in historic comeback'}]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_docs"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
